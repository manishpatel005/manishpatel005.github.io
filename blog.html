<!DOCTYPE html>
<html>
<title>Blog-Manish Patel</title>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Raleway">
<style>
body,h1,h2,h3,h4,h5 {font-family: "Raleway", sans-serif}
span[id^="more"] {display: none;}
</style>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async
        src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>
<meta name="google-site-verification" content="bvg4InVMcXnOLQELzO9Mb08WHTUcPh2SN9Ftq1-D7Hc" />
<body class="w3-light-grey">

<!-- w3-content defines a container for fixed size centered content, 
and is wrapped around the whole page content, except for the footer in this example -->
<div class="w3-content" style="max-width:1400px">

<!-- Header -->
<header class="w3-container w3-center w3-padding-32"> 
  <h1><b>The Anvikshik</b></h1>
  <!--<p>Welcome to the blog of <span class="w3-tag">Manish</span></p>-->
</header>

<!-- Grid -->
<div class="w3-row">

<!-- Blog entries -->
<div class="w3-col l8 s12">
  <!-- Blog entry -->
  <div class="w3-card-4 w3-margin w3-white">
    <img src="/blog_images/ir0_seo.jpeg" alt="SE" style="width:100%">
    <div class="w3-container">
      <h3><b>Information Storage and Retrieval-0</b></h3>
      <h5>Why this topic ?, <span class="w3-opacity">August 04, 2020</span></h5>
    </div>

    <div class="w3-container">
        <p>Two years ago, I had no idea of this topic. <br><br>
            One day, I got to know that a lot of people are dying to take this 
            Course called Information Retrieval. I thought to myself-let's give
            it a try and see what is this heck all about and if I don't like
            it, I can switch in a week. The professor of this course was 
            Dr. Caverlee.
            <span id="dots_0">...</span><span id="more_0"><br><br> 
            One week into this course, and I fell in love with it! I remember 
            our first assignment-SEO Optimization. We were given a random 
            term-sajfd hfafbjhd-that was not present on any 
            search engine and we had to make webpages or do anything that was
            ethical so that when anyone searched this random term, our pages 
            should show up as the result of the query. The page that will be
            on top will be awarded win bonus points. People went crazy. Some
            build websites, some made youtube videos, others made github repos. 
            One person made a Linked profile of person named sajfd hfafbjhd. 
            Another claimed to be scientist and wrote a research of this phenomenon
            called sajfd hfafbjhd. I made webpages, added references to this term
            in all social media pages. I also remember I made a business page for a mall
            with this term and asked my friends to like it. <br><br>
           
            Believe it or not, it started showing up on top of the results. I 
            need to give credits to my roommate Nikhil who made a school with 
            this name in the middle of a lake. The fun part is when one day my 
            friend Das was booking an Uber he found that this mall was being 
            shown as one of the pickup points. Another fun thing happend was 
            when one stranger rated my business and said- Amazing mall! 
            I was like- No bro! There is no such mall. I decided to delete it
            later on. <br><br>
						
            <img src="/blog_images/sajfd.png" alt="mall_review" style="width: 100%">
            <br><br>
						I learned so much from this course that I believe it has become one of
            my major interests and want to now share it with people. I also enjoy 
            writing, so I thought let me have two aims with one arrow. Please enjoy 
            my blog and feel free to drop any suggestions. <br><br>
            Thanks! 
            <br><br>
            Image credit: <a href="https://www.re-work.co/">rework</a>
            </span>
        </p>
      <div class="w3-row">
        <div class="w3-col m8 s12">
          <p><button class="w3-button w3-padding-large w3-white w3-border" onclick="expandRead(this)" id="0"><b>READ MORE »</b></button></p>
        </div>
				<div class="w3-col m4 w3-hide-small">
          <p><button class="w3-button w3-padding-large w3-border w3-right" onclick="expandComments(this)" id="0"><b>Comments  </b></button></p>
        </div>
			</div>
			 <div class="w3-container utterances"  id="comments_0" style="display:none;">
					<script src="https://utteranc.es/client.js"
        	repo="manishpatel005/manishpatel005.github.io"
        	issue-term="pathname"
        	theme="github-light"
        	crossorigin="anonymous"
        	async>
					</script>
        </div>
    </div>
  </div>
  <hr>

  <!-- Blog entry -->
  <div class="w3-card-4 w3-margin w3-white">
  <img src="/blog_images/ir_1_shakespeare.jpg" alt="Norway" style="width:100%">
    <div class="w3-container">
      <h3><b>Information Storage and Retrieval-1</b></h3>
      <h5>Boolean Retrieval, <span class="w3-opacity">August 05, 2020</span></h5>
    </div>

    <div class="w3-container">
    	<p>
				
      	In today's post, we will see an example of information retrieval
					-Boolean Retrieval. Suppose we want to find which plays of Shakespeare from<i> 
					Shakespeare's Collected Works</i>, contain the words Brutus AND Caesar
					AND NOT Calpurnia. There are multiple ways to do it.
					One way is to search every document(using computers) and note down which documents
					contains Brutus and Caesar but not Calpurnia. 
					<span id="dots_1">...</span><span id="more_1">
					<br><br> 
					
					<img src="/blog_images/term_incidence.png" alt="term_incidence" style="width: 100%">		
					<tt>Fig1. A term-document incidence matrix</tt><br><br>
					
					Another way is to index the documents in advance and create a matrix
					as shown in the Fig 1. where for each play(column) we mark the cells 1 
					if it contains the word(row). It is also called term-document 
					incidence matrix. <br><br>
					To answer the query: Brutus AND Caesar AND NOT Calpurnia, we take vectors
					of the first two terms and AND it with the complement of the last term i.e.
					<code>110100 and 110111 and 101111 = 100100 </code>. Thus, the answer 
					is <i>Antony and Cleopatra and Hamlet</i>. Since this model contains 0 and 1 for
					occurence or abscene of a word, it is called Boolean retrieval. The 
					problem with the above solution is that the matrix becomes too big for
					computer's memory for large corpus of documents containing distinct
					terms. <br><br>
				If we look closely we find that the matrix is sparse i.e only a small 
				subset of words are present in a document. Thus an effective way to
				store the presence of words in documents is to record only 1s and create
				an inverted index.
				
				<img src="/blog_images/inverted_index.png" alt="inverted_index" style="width: 100%" >
				
				<tt>Fig2. An inverted index with a collection of words on left
							side(called dictionary) and a list of documents in which the term
							occurs(called postings).</tt><br><br>
				Fig2. shows an inverted index for the terms made by creating a list of the
				documents in which the term occurs. Now for the query: Brutus AND Caesar
				AND NOT Calpurnia, we locate Brutus, Caesar, and Calpurnia and retrieve
				their postings and find the intersection between first two and then remove
				the words that is present in Calpurnia. That is from the intersection of
				postings of Brutus and Caesar we get <code>1,2,4</code>. If we remove
				<code>4</code> from it, we get the result as <code>1,2</code> which is 
				<i>Antony and Cleopatra and Hamlet</i>. <br><br>
				Often on Leetcode and other sites, we find problems such as intersection of
				two lists or k lists. This is a perfect instance where rubber meets the
				road. For e.g. if you have two sorted lists 
				of roughly equal size and want to find the common elements between 
				them, the best approach woulld be to use two pointers. But
				if one of them is very large, then it would make more sense to apply 
				binary search for the elements present in shorter list. <br><br>
				Now if you have multiple lists of varying size then you can either 
				sort them and start by finding common with the two smallest lists and
				then its result with next smallest and so on, or you can handle two
				lists at a time and form a hierarchical way to find the intersection.
				The best approach usually is the one which tends to be most simple
				and handles the constraints well. <br><br>
				References- <a href="https://nlp.stanford.edu/IR-book/html/htmledition/an-example-information-retrieval-problem-1.html">
				Manning, Raghavan, Schultze</a>  <br>
				Image Credits- <a href="https://www.shakespeare.org.uk/visit/shakespeares-birthplace/">shakespeare birthplace trust</a>
				</span>
      </p>
      <div class="w3-row">
        <div class="w3-col m8 s12">
          <p><button class="w3-button w3-padding-large w3-white w3-border" onclick="expandRead(this)" id="1"><b>READ MORE »</b></button></p>
        </div>
        <div class="w3-col m4 w3-hide-small">
          <p><button class="w3-button w3-padding-large w3-border w3-right" onclick="expandComments(this)" id="1"><b>Comments  </b></button></p>
        </div>
      </div>
			<div class="w3-container utterances"  id="comments_1" style="display:none;">
					<script src="https://utteranc.es/client.js"
        	repo="manishpatel005/manishpatel005.github.io"
        	issue-term="pathname"
        	theme="github-light"
        	crossorigin="anonymous"
        	async>
					</script>
        </div>
    </div>
  </div>

  <!-- Blog entry -->
  <div class="w3-card-4 w3-margin w3-white">
  <img src="/blog_images/TF-IDF.png" alt="Norway" style="width:100%">
    <div class="w3-container">
      <h3><b>Information Storage and Retrieval-2</b></h3>
      <h5>TF-IDF, <span class="w3-opacity">August 20, 2020</span></h5>
    </div>

    <div class="w3-container">
      <p>
				In the previous post, we saw that intersection of postings resulted in
				list of common postings for the query. <i>Does it matter in which order
				should we show the result to the user?</i> It turns out that it does matter.
				<span id="dots_2">...</span><span id="more_2">
				<br><br>
				<img src="/blog_images/google_ctr.png" alt="term_incidence" style="width: 100%">
				<tt>Fig1. Ranking of webpages vs CTR</tt>
				<br><br>
				We can see in the figure 1 that the site that is ranked 1 has CTR (click-through rate)
				of 34% while the next site that is ranked 2 has CTR of 17%. This exponential decrease
				shows that 60% people tend to find their information need satisfied from first three 
				sites. In another study it has been found that the order of relevance matter i.e
				if the ranked 1 site(most relevant) is swapped with ranked 2 site(less relevant), then
				CTR of rank2 increases. Hence it is important to factor in the ranks when retrieving 
				the documents for a given query. <br><br>
				The next logical step to rank two or more documents for a free-form query such as we type
				in search engines (as opposed to the boolean query of last post) is to find the number
				of occurences of the query term <i>t</i> in the document <i>d</i>. To calculate the score/rank
				we find the frequency of all terms of query in the documents, sum them up
				and rank them in decreasing order. This weighting is called <i>term frequency</i>.
				<img src="/blog_images/shakespeare_count_terms.png" alt="inverted_index" style="width: 100%" >
				
				<tt>Fig2. Frequency of the terms in the documents</tt><br><br>
				
				Figure 2 shows the number of occurences of the terms (raw term frequency) 
				in the documents. But the raw term frequency has problem that relevancy does not increase
				with term frequency i.e. a document with tf=10 is more relevant than a document with tf=1
				but not 10 times more relevant. Thus we can solve this problem by taking logarithm of <i>tf</i>
				for term <i>t</i> in document <i>d</i>:
				$$w_{t,d}= 1+log_{10}tf$$ 
				Another problem is that all terms are considered equally important
				when assessing the relevancy. However, this is not true. For instance in a set of documents
				from law industry, the term <i>legal</i> will be in almost all the documents. So we need 
				to attenuate the occurence of frequent terms and increase weight for rare terms. This 
				can be done by using <i>document frequency</i> which is defined as the number of documents
				that contain the term <i>t</i>. To weight <i>tf</i> we will use <i>inverse document frequency</i>
				which is defined as:
				$$ idf_t= \log \frac{N}{df_t} $$
				where N is the number of documents in the collection. This brings us an important milestone in IR
				which is tf-idf weighting and defined as:
				$$ w_{t,d}= (1+log_{10}tf) * \log \frac{N}{df_t} $$
				tf-idf weight increses with the number of occurences within a document(term-frequency) and 
				increases with the rarity of the term in the collection (inverse document frequency).
				
				<img src="/blog_images/tf_idf_weights.png" alt="inverted_index" style="width: 100%" >
				<tt>Fig3. tf-idf weights for the terms in the documents</tt><br><br>
				
				For our initial query of:<i>Brutus and Caesar but not Calpurnia</i>, the score for
				<i>Anthony and Cleopatra</i> will be <code>1.21 + 8.59=9.80</code> while the score for
				<i>Hamlet</i> will be <code>1.0+1.51=2.51</code>. Thus,<i>Anthony and Cleopatra</i>
				is more relevant for the query and should be displayed above <i>Hamlet</i>. <br><br>
				
				Image Credits for ranking- <a href="https://www.sistrix.com/blog/why-almost-everything-you-knew-about-google-ctr-is-no-longer-valid/">Sistrix</a> <br>
				Image Credits for shakespeare term matrix- <a href="https://people.engr.tamu.edu/caverlee/index.html#teaching">Prof. Cav</a><br>
				Image Credits for title figure- <a href="https://www.seobility.net/en/wiki/TF*IDF">Seobility</a>
				
				</span>
			</p>
      <div class="w3-row">
        <div class="w3-col m8 s12">
          <p><button class="w3-button w3-padding-large w3-white w3-border" onclick="expandRead(this)" id="2"><b>READ MORE »</b></button></p>
        </div>
        <div class="w3-col m4 w3-hide-small">
          <p><button class="w3-button w3-padding-large w3-border w3-right" onclick="expandComments(this)" id="2"><b>Comments  </b></button></p>
        </div>
      </div>
			<div class="w3-container utterances"  id="comments_2" style="display:none;">
					<script src="https://utteranc.es/client.js"
        	repo="manishpatel005/manishpatel005.github.io"
        	issue-term="pathname"
        	theme="github-light"
        	crossorigin="anonymous"
        	async>
					</script>
       </div>
    </div>
  </div>
	
	 <!-- Blog entry -->
  <div class="w3-card-4 w3-margin w3-white">
  <img src="/blog_images/ir_3_vs.jpg" alt="Vector in Space" style="width:100%">
    <div class="w3-container">
      <h3><b>Information Storage and Retrieval-3</b></h3>
      <h5>Vector Space, <span class="w3-opacity">August 21, 2020</span></h5>
    </div>

    <div class="w3-container">
    	<p>
				
      	In the last post, we saw how to calculate the tf-idf weights for the terms
				the documents. Today, we will see how we can use it in a different way. <br><br>
				
				<b>Gerald Salton</b>, the father of information retrieval introduced the concept
				of vector space where each document can be treated as a vector of 
				tf-idf weights \( \in R^{|V|} \) thus leading to a |V| dimensional real-valued
				vector space. Then terms can be treated as axes and documents as vector in this 
				vector space. <span id="dots_3">...</span><span id="more_3">
				
				<img src="/blog_images/vector_space.png" alt="inverted_index" style="width: 100%" >
				<tt>Fig1. Vector space where terms are axes, while query and documents are vectors</tt><br><br>
				
				For example, in the figure 1, we can suppose the terms Weak and Strong to be the two axes- x and y respectively.
				Since the document \(d_1\) is semantically related to Strong, vector of  \(d_1\) will be closer to y axis, while
				the document \(d_3\) is semantically related to Weak, vector of  \(d_3\) will be closer to x-axis. <br><br>
				On the other hand, \(d_2\) contains references to both Weak and Strong and thus it's vector will be in the middle.
				For the query: <i>weak strong</i>, which could be also be represented as vector (consider it as short document),
				we find that its vector is near the vector of \(d_2\) as it contains references to both Weak and Strong. <br><br>
				
				Now, we can rank the documents based on the similarity or proximity of the query vector with the vector
				of the documents. <i>The question is how do we find the similarity of two vectors?</i> <br><br>
				
				Euclidean distance is not a good option since we can see in the figure itself that distance between q and \(d_2\)
				is larger compared to distance between q and \(d_1\), although q is semantically closer to \(d_2\).
				Angle betweent the vectors will be a good idea. The smaller the angle the better the similarity. In fact, we
				can use the cosine of the angles since cosine of two vectors is their dot product if they are 
				length normalized. We need length normalization to account for documents that are similar but have
				different lengths. <br>
				
				$$ cos(q,d)= \frac{\Sigma_{i=1}^{|V|} q_i d_i}{\sqrt{\Sigma_{i=1}^{|V|} q_{i}^{2}} \sqrt{\Sigma_{i=1}^{|V|} d_{i}^{2}}}$$
				where \(q_i\) is tf-idf weight of term i in the query and \(d_i\) is tf-idf weight of term i in the document. 
				The denominator represents that query and documents are normalized. <br><br>
				
				Let's take an example to understand how cosine is calculated. Assume that we have three novels-
				Austen's <i>Sense and Sensibility</i> , <i>Pride and Prejudice</i> and Bronte's <i>Wuthering Heights</i>.
				We take three terms with normalized log term frequency (we don't do idf-weighting to keep it simple) as shown
				in the figure 2.
				
				<img src="/blog_images/tf_vs.png" alt="inverted_index" style="width: 100%" >
				<tt>Fig2. Normalized log term-frequency weights of SaS,PaP,and WH</tt><br><br>
				
				Then, $$cos(SaS, Pap) = 0.996 * 0.993 + 0.087 * 0.120 + 0 = 0.999$$
				$$cos(SaS, WH) = 0.996 * 0.847 + 0.087 * 0.466 + 0.017 *0.254 = 0.888$$
				$$cos(PaP, WH) = 0.993 * 0.847 + 0.120 * 0.466  +  0 = 0.896$$
				
				It can be seen that cos(SaS, PaP) is greater than other two which is obvious
				since SaS and PaP are both written by Austen. <br><br>
				
				One important thing we can learn from vector space is how to turn the simple matrix
				of numbers into a n-dimensional space. An example of this concept would be the 
				word embeddings- where we turn or map words to a bunch of real numbers (Tomas Mikolov, 2013)
				and words that are alike are nearby while words that are different are far away in this n-dimensional space. 
					
				</span>
      </p>
      <div class="w3-row">
        <div class="w3-col m8 s12">
          <p><button class="w3-button w3-padding-large w3-white w3-border" onclick="expandRead(this)" id="3"><b>READ MORE »</b></button></p>
        </div>
        <div class="w3-col m4 w3-hide-small">
          <p><button class="w3-button w3-padding-large w3-border w3-right" onclick="expandComments(this)" id="3"><b>Comments  </b></button></p>
        </div>
      </div>
			<div class="w3-container utterances"  id="comments_3" style="display:none;">
					<script src="https://utteranc.es/client.js"
        	repo="manishpatel005/manishpatel005.github.io"
        	issue-term="pathname"
        	theme="github-light"
        	crossorigin="anonymous"
        	async>
					</script>
      </div>
    </div>
  </div>

<!-- END BLOG ENTRIES -->
</div>

<!-- Introduction menu -->
<div class="w3-col l4">
  <!-- About Card -->
  <div class="w3-card w3-margin w3-margin-top">
      <!--<img src="/w3images/avatar_g.jpg" style="width:100%"> -->
    <div class="w3-container w3-white">
      <h4><b>Manish Patel</b></h4>
      <p>Howdy!<br>
       I am a recent grad from Texas A&amp;M University where I worked in Information
				Storage and Retrieval, NLU, and Image Segmentation.   
       I have interned in Google Search team (Mountain View, US) and worked in C-DOT (New Delhi, India) as Research Engineer. 
       I love solving challenging problems in the field of algorithm design and have 5+ years of experience in algorithm design and coding. 
      </p>
      <p>Having brought-up in various parts of India, I enjoy traveling to new
				places and making new friends. In my free time, I love reading English
				classics,particulary realist fiction, and playing badminton. Some of 
				my favorite books are - Anna Karenina, The Count of Monte Cristo, The
				Picture of Dorian Gray, 1984, Les Miserables, Karmabhoomi, The Art of
				War, Great Expectations, The Odyssey etc. In badminton, my favorite players are-
      	Lee Chong Wei, Lin Dan(sad to hear his retirement), Kento Momota, 
				PV Sindu and Victor Axelson.  
      </p>
      <p>
      The name of this blog --The Anvikshik-- comes from a Sanskrit word Anviskhiki which roughly means the science of searching.
			<!--whether
			inwards(spiritual) or outwards(reasoning/logic). -->Since my interests lie in the 
			field of information retrieval, I couldn't find a better word than this to describe the blog.
			My intention of creating this blog is to share my enthusiasm of this niche domain and encourage people to generate
      new ideas to solve the challenging problems of today.
			<!--refers to means a person or craftsmen who is skilled in the use of Machine tools such as Neural Networks, SVM, Regression etc. 
      Although dictionaries have defined only the word machinist, I heard the term once used by someone but unfortunately could not remember it. I dedicate it to the
      unknown soul. -->  
      </p>
    </div>
  </div><hr>
	
  
  <!-- Posts -->
	<!-- 
  <div class="w3-card w3-margin">
    <div class="w3-container w3-padding">
      <h4>Popular Posts</h4>
    </div>
    <ul class="w3-ul w3-hoverable w3-white">
      <li class="w3-padding-16">
        <img src="/w3images/workshop.jpg" alt="Image" class="w3-left w3-margin-right" style="width:50px">
        <span class="w3-large">Lorem</span><br>
        <span>Sed mattis nunc</span>
      </li>
      <li class="w3-padding-16">
        <img src="/w3images/gondol.jpg" alt="Image" class="w3-left w3-margin-right" style="width:50px">
        <span class="w3-large">Ipsum</span><br>
        <span>Praes tinci sed</span>
      </li> 
      <li class="w3-padding-16">
        <img src="/w3images/skies.jpg" alt="Image" class="w3-left w3-margin-right" style="width:50px">
        <span class="w3-large">Dorum</span><br>
        <span>Ultricies congue</span>
      </li>   
      <li class="w3-padding-16 w3-hide-medium w3-hide-small">
        <img src="/w3images/rock.jpg" alt="Image" class="w3-left w3-margin-right" style="width:50px">
        <span class="w3-large">Mingsum</span><br>
        <span>Lorem ipsum dipsum</span>
      </li>  
    </ul>
  </div>
  <hr> 
  -->
  <!-- Labels / tags -->
  <div class="w3-card w3-margin">
    <div class="w3-container w3-padding">
      <h4>Tags</h4>
    </div>
    <div class="w3-container w3-white">
    <p><span class="w3-tag w3-light-grey w3-margin-bottom">Information Retrieval</span> <span class="w3-tag w3-light-grey w3-small w3-margin-bottom">SEO</span> <span class="w3-tag w3-light-grey w3-small w3-margin-bottom">TF-IDF</span>
      <span class="w3-tag w3-light-grey w3-small w3-margin-bottom">Vector Space</span> 
			<span class="w3-tag w3-light-grey w3-small w3-margin-bottom">BM25</span> 
			<span class="w3-tag w3-light-grey w3-small w3-margin-bottom">Recommder Systems</span>
			<span class="w3-tag w3-light-grey w3-small w3-margin-bottom"><img src="https://hitcounter.pythonanywhere.com/count/tag.svg" alt="Hits"></span>
			
    </p>
    </div>
  </div>
  
<!-- END Introduction Menu -->
</div>

<!-- END GRID -->
</div><br>

<!-- END w3-content -->
</div>

<!-- Footer -->
<footer class="w3-container w3-dark-grey w3-padding-32 w3-margin-top">
  <button class="w3-button w3-black w3-disabled w3-padding-large w3-margin-bottom">Previous</button>
  <button class="w3-button w3-black w3-disabled w3-padding-large w3-margin-bottom">Next »</button>
  <p>Powered by <a href="https://www.w3schools.com/w3css/default.asp" target="_blank">w3.css</a></p>
</footer>

<script>
function expandRead(button) {
	var id = button.id;
	var dots_id = 'dots_' + id;
	var more_id = 'more_' + id;
	
	
  var dots = document.getElementById(dots_id);
  var moreText = document.getElementById(more_id);
  var btnText = document.getElementById(id);
	
	
  if (dots.style.display === "none") {
    dots.style.display = "inline";
    btnText.innerHTML = "Read more"; 
    moreText.style.display = "none";
		
  } else {
    dots.style.display = "none";
    btnText.innerHTML = "Read less"; 
    moreText.style.display = "inline";
	}
}
	
function expandComments(button) {
	var id = button.id;
	var comments_id = 'comments_' + id;
	var moreComments = document.getElementById(comments_id);
	
  if (moreComments.style.display === "none") { 
    moreComments.style.display = "block";
  } else {
    moreComments.style.display = "none";
	}
}
</script>
</body>
</html>

