<!DOCTYPE html>
<html>
	<title>Blog-Manish Patel</title>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Raleway">
	<style>
		body,
		h1,
		h2,
		h3,
		h4,
		h5 {
			font-family: "Raleway", sans-serif
		}

		span[id^="more"] {
			display: none;
		}

	</style>
	<!-- <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> -->
	<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
	<meta name="google-site-verification" content="bvg4InVMcXnOLQELzO9Mb08WHTUcPh2SN9Ftq1-D7Hc" />
	<!-- Following three are for collapsible read more button starting  from id 5-->
	<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css">
	<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
	<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"></script>

	<body class="w3-light-grey">

		<!-- w3-content defines a container for fixed size centered content, 
and is wrapped around the whole page content, except for the footer in this example -->
		<div class="w3-content" style="max-width:1400px">

			<!-- Header -->
			<header class="w3-container w3-center w3-padding-32">
				<h1><b>The Anvikshik</b></h1>
				<!--<p>Welcome to the blog of <span class="w3-tag">Manish</span></p>-->
			</header>

			<!-- Grid -->
			<div class="w3-row">

				<!-- Blog entries -->
				<div class="w3-col l9 s12">
					
                    <!-- Blog entry -->
					<div class="w3-card-4 w3-margin w3-white">
						<div class="w3-container">
							<h3><b><a href="https://www.wikihow.com/Build-a-Robot-at-Home">Obstacle Avoiding Robot</a> </b></h3>
							<h5><span class="w3-opacity">February 16, 2022</span></h5>
						</div>

						<div class="w3-container">
							<p>
								Obstacle avoiding robot is a robot that could move around freely by avoiding the obstacles. 
                                There are a lot of tutorials on the internet that you could lookup to create one yourself. However, If I had to recommend,
                                I would say <a href="https://dronebotworkshop.com/tb6612fng-h-bridge/" > dronebotworkshop </a>is one of the best.
                                The main reason I have created this post is to share the mistakes I did so that you don't repeat it. Let's start. <br><br>
                                <img src="/blog_images/robot.jpg" alt="obstacle_avoiding_robot" style="width: 90%">
                                <ul>
                                    <li>Mistake 1: Servo motors vs DC motors</li>
                                    I thought initally both are motors and could be used interchangeably but I was wrong. Servo motors are precision-based motors that don't rotate more than 180 degress and are used as robotic limbs, rudder control or for car-wiper kind of movement. Although you can do some adjustments (like removing potentiometer) to create a continuous rotating servo motors but it is very hard. Also, it is hard to find continuous rotating servo motors. <br><br>
                                    
                                    DC motors or battery-operated DC motors, on the other hand, can rotate continuosly and are used as wheels of cars etc. <br>
                                    There are another kind of motors called Stepper motors that are like fine-tuned servo motors and are used for 3d printer kind of situations. <br><br>
                                    
                                    So use a battery operated DC motors for a robot that needs to rotate continuosly. I used DC motors with voltage range 3~6 V. Remember more the volatage required for a motor, more the voltage is needed in a battery. <br><br>
                                    
                                    <li> Mistake 2: L298N module vs TB6612FNG module</li>
                                    There are a lot of tutorials with L298N module and it's very easily available as well. Initially, I used L298N module to drive the motors.  It was working great but after some time the motors would start to slow down and eventually stop. There was only some noise but motors wouldn't work. Replaced it with new battery and same thing happened again. I did a digup on the internet and found that L298N module has very poor efficieny(around 45%) and it is dropping the voltage really quick. So as a hack, I powered the logic with arduino's 5v but still it wouldn't work for long. <br><br>
                                    I searched and found about another H bridge circuit-TB6612FNG. It's a really awesome module and I would advise you to use it rather than L298N module. It has very high efficieny(around 95%) and it can provide constant volatage/current to the motors. <br><br>
                                    
                                    <li> Mistake 3: Not soldering module</li>
                                    The TB6612FNG module comes with male header pins that are not soldered. I thought I could insert it into breadboard using the pins and it should work. But it didn't. So I had to solder it to make it work. I guess this was a silly mistake when I look back. But then  that's the part of learning.
                            
                                </ul>
                                The whole experience of making the robot was very valuable. I wish I would have done it earlier. My next plan is to make quadcopters.
                                
								
								</span>
							</p>
							<div class="w3-row">
								<div class="w3-col m8 s12">
									<p><!-- <button class="w3-button w3-padding-large w3-white w3-border" onclick="expandRead(this)" id="2"><b>READ MORE »</b></button>--></p>
								</div>
								<div class="w3-col m4 w3-hide-small">
									<p><button class="w3-button w3-padding-large w3-border w3-right" onclick="expandComments(this)" id="2"><b>Comments  </b></button></p>
								</div>
							</div>
							<div class="w3-container utterances" id="comments_2" style="display:none;">
								<script src="https://utteranc.es/client.js" repo="manishpatel005/manishpatel005.github.io" issue-term="pathname" theme="github-light" crossorigin="anonymous" async>
								</script>
							</div>
						</div>
					</div>

                    
					<!-- Blog entry -->
					<div class="w3-card-4 w3-margin w3-white">
						<!--<img src="/blog_images/ir_1_shakespeare.jpg" alt="Norway" style="width:100%"> -->
						<div class="w3-container">
							<h3><b><a href="https://en.wikipedia.org/wiki/Boolean_model_of_information_retrieval">Boolean Retrieval</a></b></h3>
							<h5><span class="w3-opacity">August 05, 2020</span></h5>
						</div>

						<div class="w3-container">
							<p>
								Suppose we want to find which plays of Shakespeare from<i>
								Shakespeare's Collected Works</i>, contain the words Brutus AND Caesar
								AND NOT Calpurnia. There are multiple ways to do it.
								One way is to search every document(using computers) and note down which documents
								contains Brutus and Caesar but not Calpurnia.

								<img src="/blog_images/term_incidence.png" alt="term_incidence" style="width: 100%">
								<tt>Fig1. A term-document incidence matrix</tt><br><br>

								Another way is to index the documents in advance and create a matrix
								as shown in the Fig 1. where for each play(column) we mark the cells 1
								if it contains the word(row). It is also called term-document
								incidence matrix. <br><br>
								To answer the query: Brutus AND Caesar AND NOT Calpurnia, we take vectors
								of the first two terms and AND it with the complement of the last term i.e.
								<code>110100 and 110111 and 101111 = 100100 </code>. Thus, the answer
								is <i>Antony and Cleopatra and Hamlet</i>. Since this model contains 0 and 1 for
								occurence or abscene of a word, it is called Boolean retrieval. The
								problem with the above solution is that the matrix becomes too big for
								computer's memory for large corpus of documents containing distinct
								terms. <br><br>
								If we look closely <span id="dots_1">...</span><span id="more_1">
								we find that the matrix is sparse i.e only a small
								subset of words are present in a document. Thus an effective way to
								store the presence of words in documents is to record only 1s and create
								an inverted index.

								<img src="/blog_images/inverted_index.png" alt="inverted_index" style="width: 100%">

								<tt>Fig2. An inverted index with a collection of words on left
									side(called dictionary) and a list of documents in which the term
									occurs(called postings).</tt><br><br>
								Fig2. shows an inverted index for the terms made by creating a list of the
								documents in which the term occurs. Now for the query: Brutus AND Caesar
								AND NOT Calpurnia, we locate Brutus, Caesar, and Calpurnia and retrieve
								their postings and find the intersection between first two and then remove
								the words that is present in Calpurnia. That is from the intersection of
								postings of Brutus and Caesar we get <code>1,2,4</code>. If we remove
								<code>4</code> from it, we get the result as <code>1,2</code> which is
								<i>Antony and Cleopatra and Hamlet</i>. <br><br>
								Often on Leetcode and other sites, we find problems such as intersection of
								two lists or k lists. This is a perfect instance where rubber meets the
								road. For e.g. if you have two sorted lists
								of roughly equal size and want to find the common elements between
								them, the best approach woulld be to use two pointers. But
								if one of them is very large, then it would make more sense to apply
								binary search for the elements present in shorter list. <br><br>
								Now if you have multiple lists of varying size then you can either
								sort them and start by finding common with the two smallest lists and
								then its result with next smallest and so on, or you can handle two
								lists at a time and form a hierarchical way to find the intersection.
								The best approach usually is the one which tends to be most simple
								and handles the constraints well. <br><br>
								References- <a href="https://nlp.stanford.edu/IR-book/html/htmledition/an-example-information-retrieval-problem-1.html">
								Manning, Raghavan, Schultze</a> <br>
								Image Credits- <a href="https://www.shakespeare.org.uk/visit/shakespeares-birthplace/">shakespeare birthplace trust</a>
								</span>
							</p>
							<div class="w3-row">
								<div class="w3-col m8 s12">
									<p><button class="w3-button w3-padding-large w3-white w3-border" onclick="expandRead(this)" id="1"><b>READ MORE »</b></button></p>
								</div>
								<div class="w3-col m4 w3-hide-small">
									<p><button class="w3-button w3-padding-large w3-border w3-right" onclick="expandComments(this)" id="1"><b>Comments  </b></button></p>
								</div>
							</div>
							<div class="w3-container utterances" id="comments_1" style="display:none;">
								<script src="https://utteranc.es/client.js" repo="manishpatel005/manishpatel005.github.io" issue-term="pathname" theme="github-light" crossorigin="anonymous" async>
								</script>
							</div>
						</div>
					</div>

					<!-- Blog entry -->
					<div class="w3-card-4 w3-margin w3-white">
						<!--<img src="/blog_images/TF-IDF.png" alt="Norway" style="width:100%"> -->
						<div class="w3-container">
							<h3><b><a href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf">TF-IDF</a> </b></h3>
							<h5><span class="w3-opacity">August 20, 2020</span></h5>
						</div>

						<div class="w3-container">
							<p>
								In the previous post, we saw that intersection of postings resulted in
								list of common postings for the query. <i>Does it matter in which order
								should we show the result to the user?</i> It turns out that it does matter.
								<br><br>
								<img src="/blog_images/google_ctr.png" alt="term_incidence" style="width: 100%">
								<tt>Fig1. Ranking of webpages vs CTR</tt>
								<br><br>
								We can see in the figure 1 that the site that is ranked 1 has <a href="https://en.wikipedia.org/wiki/Click-through_rate">CTR (click-through rate)</a>
								of 34% while the next site that is ranked 2 has CTR of 17%. This exponential decrease
								shows that 60% people tend to find their information need satisfied from first three
								sites. In another study it has been found that the order of relevance matter i.e
								if the ranked 1 site(most relevant) is swapped with ranked 2 site(less relevant), then
								CTR of rank2 increases. Hence it is important to factor in the ranks when retrieving
								the documents for a given query. <br><br>
								The next logical step to rank two or more documents for a free-form query such as we type
								in search engines (as opposed to the boolean query of last post) is to find the number
								of occurences of the query term <i>t</i> in the document <i>d</i>. To calculate the score/rank
								<span id="dots_2">...</span><span id="more_2">
								we find the frequency of all terms of query in the documents, sum them up
								and rank them in decreasing order. This weighting is called <i>term frequency</i>.
								<img src="/blog_images/shakespeare_count_terms.png" alt="inverted_index" style="width: 100%">

								<tt>Fig2. Frequency of the terms in the documents</tt><br><br>

								Figure 2 shows the number of occurences of the terms (raw term frequency)
								in the documents. But the raw term frequency has problem that relevancy does not increase
								with term frequency i.e. a document with tf=10 is more relevant than a document with tf=1
								but not 10 times more relevant. Thus we can solve this problem by taking logarithm of <i>tf</i>
								for term <i>t</i> in document <i>d</i>:
								$$w_{t,d}= 1+log_{10}tf$$
								Another problem is that all terms are considered equally important
								when assessing the relevancy. However, this is not true. For instance in a set of documents
								from law industry, the term <i>legal</i> will be in almost all the documents. So we need
								to attenuate the occurence of frequent terms and increase weight for rare terms. This
								can be done by using <i>document frequency</i> which is defined as the number of documents
								that contain the term <i>t</i>. To weight <i>tf</i> we will use <i>inverse document frequency</i>
								which is defined as:
								$$ idf_t= \log_{10} \frac{N}{df_t} $$
								where N is the number of documents in the collection. This brings us an important milestone in IR
								which is tf-idf weighting and defined as:
								$$ w_{t,d}= (1+log_{10}tf) * \log_{10} \frac{N}{df_t} $$
								tf-idf weight increses with the number of occurences within a document(term-frequency) and
								increases with the rarity of the term in the collection (inverse document frequency).

								<img src="/blog_images/tf_idf_weights.png" alt="inverted_index" style="width: 100%">
								<tt>Fig3. tf-idf weights for the terms in the documents</tt><br><br>

								For our initial query of:<i>Brutus and Caesar but not Calpurnia</i>, the score for
								<i>Anthony and Cleopatra</i> will be <code>1.21 + 8.59=9.80</code> while the score for
								<i>Hamlet</i> will be <code>1.0+1.51=2.51</code>. Thus,<i>Anthony and Cleopatra</i>
								is more relevant for the query and should be displayed above <i>Hamlet</i>. <br><br>

								Image Credits for ranking- <a href="https://www.sistrix.com/blog/why-almost-everything-you-knew-about-google-ctr-is-no-longer-valid/">Sistrix</a> <br>
								Image Credits for shakespeare term matrix- <a href="https://people.engr.tamu.edu/caverlee/index.html#teaching">Prof. Cav</a><br>
								</span>
							</p>
							<div class="w3-row">
								<div class="w3-col m8 s12">
									<p><button class="w3-button w3-padding-large w3-white w3-border" onclick="expandRead(this)" id="2"><b>READ MORE »</b></button></p>
								</div>
								<div class="w3-col m4 w3-hide-small">
									<p><button class="w3-button w3-padding-large w3-border w3-right" onclick="expandComments(this)" id="2"><b>Comments  </b></button></p>
								</div>
							</div>
							<div class="w3-container utterances" id="comments_2" style="display:none;">
								<script src="https://utteranc.es/client.js" repo="manishpatel005/manishpatel005.github.io" issue-term="pathname" theme="github-light" crossorigin="anonymous" async>
								</script>
							</div>
						</div>
					</div>

					<!-- Blog entry -->
					<div class="w3-card-4 w3-margin w3-white">
						<!--<img src="/blog_images/ir_3_vs.jpg" alt="Vector in Space" style="width:100%"> -->
						<div class="w3-container">
							<h3><b><a href="https://en.wikipedia.org/wiki/Vector_space" >Vector Space</a></b></h3>
							<h5><span class="w3-opacity">August 21, 2020</span></h5>
						</div>

						<div class="w3-container">
							<p>

								In the last post, we saw how to calculate the tf-idf weights for the terms
								the documents. Today, we will see how we can use it in a different way. <br><br>

								<b><a href="https://en.wikipedia.org/wiki/Gerard_Salton">Gerald Salton</a></b>, the father of information retrieval introduced the concept
								of vector space where each document can be treated as a vector of
								tf-idf weights \( \in R^{|V|} \) thus leading to a |V| dimensional real-valued
								vector space. Then terms can be treated as axes and documents as vector in this
								vector space.

								<img src="/blog_images/vector_space.png" alt="inverted_index" style="width: 100%">
								<tt>Fig1. Vector space where terms are axes, while query and documents are vectors</tt><br><br>

								For example, in the figure 1, we can suppose the terms Weak and Strong to be the two axes- x and y respectively.
								Since the document \(d_1\) is semantically related to Strong, vector of \(d_1\) will be closer to y axis, while
								the document \(d_3\) is semantically related to Weak, vector of \(d_3\) will be closer to x-axis. <br><br>
								On the other hand, \(d_2\) contains references to both Weak and Strong and thus it's vector will be in the middle.
								For the query: <i>weak strong</i>, which could be also be represented as vector (consider it as short document),
								we find that its vector is near the vector of \(d_2\) as it contains references to both Weak and Strong. <br><br>

								Now, we can rank the documents based on the similarity or proximity of the query vector with the vector
								of the documents. <i>The question is how do we find the similarity of two vectors?</i> <br><br>

								<a href="https://en.wikipedia.org/wiki/Euclidean_distance" >Euclidean distance</a> is not a good option since <span id="dots_3">...</span><span id="more_3">
								we can see in the figure itself that distance between q and \(d_2\)
								is larger compared to distance between q and \(d_1\), although q is semantically closer to \(d_2\).
								Angle betweent the vectors will be a good idea. The smaller the angle the better the similarity. In fact, we
								can use the cosine of the angles since cosine of two vectors is their dot product if they are
								length normalized. We need length normalization to account for documents that are similar but have
								different lengths. <br>

								$$ cos(q,d)= \frac{\Sigma_{i=1}^{|V|} q_i d_i}{\sqrt{\Sigma_{i=1}^{|V|} q_{i}^{2}} \sqrt{\Sigma_{i=1}^{|V|} d_{i}^{2}}}$$
								where \(q_i\) is tf-idf weight of term i in the query and \(d_i\) is tf-idf weight of term i in the document.
								The denominator represents that query and documents are normalized. <br><br>

								Let's take an example to understand how cosine is calculated. Assume that we have three novels-
								Austen's <i>Sense and Sensibility</i> , <i>Pride and Prejudice</i> and Bronte's <i>Wuthering Heights</i>.
								We take three terms with normalized log term frequency (we don't do idf-weighting to keep it simple) as shown
								in the figure 2.

								<img src="/blog_images/tf_vs.png" alt="inverted_index" style="width: 100%">
								<tt>Fig2. Normalized log term-frequency weights of SaS,PaP,and WH</tt><br><br>


								Then, <br>
								\(cos(SaS, Pap) = 0.996 * 0.993 + \) \(0.087 * 0.120 + 0 = 0.999 \) <br>
								\(cos(SaS, WH) = 0.996 * 0.847 + \) \(0.087 * 0.466 + 0.017 *0.254 = 0.888\)<br>
								\(cos(PaP, WH) = 0.993 * 0.847 + \) \(0.120 * 0.466 + 0 = 0.896\)<br><br>

								It can be seen that cos(SaS, PaP) is greater than other two which is obvious
								since SaS and PaP are both written by Austen. <br><br>

								One important thing we can learn from vector space is how to turn the simple matrix
								of numbers into a n-dimensional space. An example of this concept would be the
								<a href="https://www.tensorflow.org/text/guide/word_embeddings">word embeddings</a>- where we turn or map words to a bunch of real numbers 
								(<a href="https://papers.nips.cc/paper/2013/file/9aa42b31882ec039965f3c4923ce901b-Paper.pdf">Tomas Mikolov, 2013</a>)
								and words that are alike are nearby while words that are different are far away in this n-dimensional space.

								</span>
							</p>
							<div class="w3-row">
								<div class="w3-col m8 s12">
									<p><button class="w3-button w3-padding-large w3-white w3-border" onclick="expandRead(this)" id="3"><b>READ MORE »</b></button></p>
								</div>
								<div class="w3-col m4 w3-hide-small">
									<p><button class="w3-button w3-padding-large w3-border w3-right" onclick="expandComments(this)" id="3"><b>Comments  </b></button></p>
								</div>
							</div>
							<div class="w3-container utterances" id="comments_3" style="display:none;">
								<script src="https://utteranc.es/client.js" repo="manishpatel005/manishpatel005.github.io" issue-term="pathname" theme="github-light" crossorigin="anonymous" async>
								</script>
							</div>
						</div>
					</div>


					<!-- Blog entry -->
					<div class="w3-card-4 w3-margin w3-white">
						<!--<img src="/blog_images/tf-idf_tut_cover.png" alt="TFIDF Cover" style="width:100%"> -->
						<div class="w3-container">
							<h3><b>Tutorial on TF-IDF</b></h3>
							<h5><span class="w3-opacity">September 15, 2020</span></h5>
						</div>

						<div class="w3-container">
							<p>
								Suppose that we have two documents:</p>
							<blockquote>
								<p>Doc1: &quot;one small step for man one giant leap for mankind &quot;</p>
							</blockquote>
							<blockquote>
								<p>Doc2: &quot;one has to take small steps to reach big goals&quot;</p>
							</blockquote>
							<p>
								If we calculate the frequency of each word then it would be look something like this:
								<img src="/blog_images/tfidf_tut.png" alt="example-tfidf" style="width: 90%"> <br>
								To calculate the tf-idf of "one", we first calculate its tf which is the raw-frequency.
								thus tf of "one" is: <br>
								$$ tf("one", Doc1) = \frac{2}{10} = \frac{1}{5} = 0.2$$
								$$ tf("one", Doc2) = \frac{1}{10} = 0.1$$
								The idf of a term is constant for the entire corpus and is calculated as the logarithm of total
								number of documents in corpus divided by the number of documents that contains the term.
								Thus, the idf for term "one" is:
								$$ idf("one", {Doc1,Doc2}) = log(\frac{2}{2}) = 0$$
								Since tf-idf is defined as:
								$$ tf-idf_{(t,d)}= (1+log_{10}tf) * \log_{10} \frac{N}{df_t} $$
								we get
								$$ tf-idf_{("one",Doc1)}= (1+log_{10}0.2) * 0 = 0 $$
								$$ tf-idf_{("one",Doc2)}= (1+log_{10}0.1) * 0 = 0 $$
								Since the t-idf is zero for the word "one",
								<span id="dots_4">...</span><span id="more_4">
								it means that this word is not very informative and
								appears in all the documents. <br>
								Let's calculate the tf-idf for another word "to". The tf of "to" is:
								$$ tf("to", Doc1) = \frac{0}{10} = 0 $$
								$$ tf("to", Doc2) = \frac{2}{10} = 0.2 $$
								The idf for term "to" is:
								$$ idf("to", {Doc1,Doc2}) = log(\frac{2}{1}) = 0.301$$
								The tf-idf for "to" is:
								$$ tf-idf_{("to",Doc1)}= (1+log_{10}0) * 0.301 = 0 $$
								$$ tf-idf_{("to",Doc2)}= (1+log_{10}0.2) * 0.301 = 0.30 * .30 = 0.09 $$
								The word "to" is more interesting as it occurs twice in the second document. <br>
								Here we have taken (1+log 0) to be 0, since log 0 is undefined and we want to have weight as 0 when the term is not present. <br>
								To calculate the tf-idf score for the entire document, one can just sum up the tf-idf scores for all the individual terms.
								</span>
							</p>

							<div class="w3-row">
								<div class="w3-col m8 s12">
									<p><button class="w3-button w3-padding-large w3-white w3-border" onclick="expandRead(this)" id="4"><b>READ MORE »</b></button></p>
								</div>
								<div class="w3-col m4 w3-hide-small">
									<p><button class="w3-button w3-padding-large w3-border w3-right" onclick="expandComments(this)" id="4"><b>Comments  </b></button></p>
								</div>
							</div>
							<div class="w3-container utterances" id="comments_4" style="display:none;">
								<script src="https://utteranc.es/client.js" repo="manishpatel005/manishpatel005.github.io" issue-term="pathname" theme="github-light" crossorigin="anonymous" async>
								</script>
							</div>
						</div>
					</div>


					<!-- Blog entry -->
					<div class="w3-card-4 w3-margin w3-white">
						<!--<img src="/blog_images/hubs_cover.png" alt="Hubs and Auth cover" style="width:100%"> -->
						<div class="w3-container">
							<h3><b>Hubs and Authorities- <a href="http://pi.math.cornell.edu/~mec/Winter2009/RalucaRemus/Lecture4/lecture4.html">HITS Algorithm</a></b></h3>
							<h5><span class="w3-opacity">September 20, 2020</span></h5>
						</div>

						<div class="w3-container">

							<p>Imagine you are developing a search engine for a digital library such as IEEE Explore or arxiv and a user submits a query&nbsp;- 
							<span style="color: #ff0000;">What is attention</span> ? </p>
							<p>If you have worked in NLP or machine learning you might have heard of this mechanism called <strong>Attention</strong> introduced by 
							<a href="https://arxiv.org/abs/1706.03762">Vaswani et al</a>, in his ground-breaking research paper-&nbsp;<strong>Attention is all you need-&nbsp;</strong>
							NeurIPS 2017. It was such an important concept that it changed the course of Neural Machine Translation (and of NLP ) and led to neural architecture such as 
							Transformers, and Bidirectional Transformers(BERT) etc. See this blog post by 
							<a href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/">Jay Alammar</a> for an amazing 
							explaination on how attention works. </p>
							<p>Now if you make a simple text based search on all the papers in the library, you will get like million documents containing the term "attention" as it's 
							such a common word. If you make a tf-idf based search then the original paper by Vaswani will get even lower score than the review paper by&nbsp; 
							<a href="https://arxiv.org/pdf/1902.02181.pdf">Galassi</a> as the former have used the term attention only 97 times as opposed to the latter who have used it 
							more than 400 times.&nbsp;</p>
							<p>So the question i<em>s: how to figure out who is the authentic source of this mechanism called Attention?&nbsp;</em>It turns out that in this network 
							structure of linked environment i.e. if paper A cites paper B then it can be deemed as a link from paper A to paper B, one can use PageRank or HITS algorithm. 
							HITS algorithm was developed by Prof. Jon Kleinberg at Cornell University at the same time when PageRank was developed by Larry and Sergey at Stanford. 
							Let's see how how HITS works.</p>
							<p><strong>Hyperlink-induced Topic Search</strong> (<a href="http://pi.math.cornell.edu/~mec/Winter2009/RalucaRemus/Lecture4/lecture4.html">HITS</a>) is an 
							approach to discover the authoritative sources in context of World Wide Web (www) where the number of pages is enormous and is linked to each other by 
							hyperlinks (incoming and outgoing). But this approach could also be used for the linked structure discussed above.&nbsp;</p>
							<p><strong>Authorative sources</strong> mean the sources which provide valuable information on the subject and has been considered as the "authority" by others due to its virtue of originality or popularity. 
							For example, for a query on "<em>Texas A&amp;M University"</em>, the homepage of <a href="https://www.tamu.edu/" >Texas A&amp;M</a> can be considered as the authority.&nbsp; Pages of goverment websites might also be considered as the authorities for the query. These are the pages truly relevant to the given query and are expected by the users from the search engine.</p>
							<p>However, there is another category of the pages called <strong>hubs</strong>, whose role is to advertise the authoritative pages i.e. they contain links to "authority" pages and help the search engine move in the right direction. For example, "usnews.com" and "timeshighereducation.com" - the sites that ranks the schools can be considered as hubs.&nbsp; </p>

							<p>Thus,</p>
							<ul>
								<li>A good hub page for a topic points to many authorative pages on that topic.</li>
								<li>A good authority page for a topic is pointed to by many good hubs for that topic.</li>
							</ul>
							<p>For the query- "what is attention", we would have a network graph like this:</p>

							<img src="/blog_images/hubs_and_auth.png" alt="hubs_and_authority_example" style="width: 60%"> <br>
							<div id="more_5" class="collapse">
								<p>The idea behind HITS algorithm is to find out the good hubs and authorities for a topic by assigning two numbers to a page: hub score and authority score. To start with something, we first do a regular keyword search for the topic and call the search result as&nbsp;<strong>root set.</strong>&nbsp;Typically, it consists of 200 to 1000 nodes.&nbsp; </p>
								<img src="/blog_images/root_base_set.png" alt="root_and_base_set" style="width: 60%"> <br>
								<tt>Fig1. Root set consists of examples from original query while base set consists of root set + incoming and outgoing links</tt><br><br>
								<p>Then we find all the nodes that are either pointed by the root set or points to the root set. This we call as <strong>base set</strong>( it includes the root set). Typically, it consists of around 5000 nodes.&nbsp;</p>
								<p>Next we do the following:</p>
								<ol>
									<li>For each page x in the base set:</li>
									<li>Initiliaze x: hub(x) := 1 and auth(x) := 1</li>
									<li>Repeat the following update until convergence:
										<ul>
											<li style="text-align: left;">hub(x) := &sum; auth(x')&nbsp; (where x' is pointed by x)</li>
											<li style="text-align: left;">auth(x) = &sum; hub(x')&nbsp;&nbsp; (where x' points to x)</li>
											<li style="text-align: left;">Scale down or normalize the hub(x) and auth(x) by l2 norm (square root of sum of squares)</li>
										</ul>
										<img src="/blog_images/combine_hub_auth.png" alt="combine_hubs_and_authority_example" style="width: 80%"> <br>
									</li>
									<li>After convergence, the pages with highest hub scores will be the top hubs while the page with highest auth scores will be the top authorities.</li>
								</ol>

								<p style="text-align: left;">Let us take a small example to understand how it works:</p>

								<img src="/blog_images/hits_example.png" alt="hits_example" style="width: 100%"> <br>
								<tt>Fig2. Linked structure graph. We assign A to represent attention, B to represent BERT and N to represent NMT in the following example. </tt><br><br>
								<p style="text-align: left;"><strong>Round 0</strong>: Initialize</p>
								<table style="border-collapse: collapse; width: 46.8666%;" height="98" border="1">
									<tbody>
										<tr>
											<td style="width: 43.0337%; text-align: center;"><strong>Hubs score</strong></td>
											<td style="width: 47.1973%; text-align: center;"><strong>Auth score</strong></td>
										</tr>
										<tr>
											<td style="width: 43.0337%;">hub (A) = 1</td>
											<td style="width: 47.1973%;">auth (A) = 1</td>
										</tr>
										<tr>
											<td style="width: 43.0337%;">hub (B) = 1</td>
											<td style="width: 47.1973%;">auth (B) = 1</td>
										</tr>
										<tr>
											<td style="width: 43.0337%;">hub (N) = 1</td>
											<td style="width: 47.1973%;">auth (N) = 1</td>
										</tr>
									</tbody>
								</table>

								<p><strong>Round 1</strong>:</p>
								<p>First let's calculate the hubs score.</p>
								<p>Since A points to A itself and N, we add the authority score of A and N from previous round to get the new_hub score for A which is = 1 + 1 = 2.</p>
								<p>Since B points to A, B and N, we add the authority score of A, B, and N from previous round to get the new_hub score for B which is = 1 + 1 + 1 = 3.</p>
								<p>Since N does not point anywhere,&nbsp; we have the new_hub score for N which is = 0.</p>
								<p>The l2 norm for new_hub will be =&nbsp;&radic;(2^2 + 3^2 + 0^ 2) = 3.60</p>
								<p>Dividing each element of new_hub score, we have new hubs score as follows:</p>
								<table style="border-collapse: collapse; width: 22.4014%;" height="77" border="1">
									<tbody>
										<tr>
											<td style="width: 100%; text-align: center;">Hubs Score</td>
										</tr>
										<tr>
											<td style="width: 100%;">hub (A) = 0.55</td>
										</tr>
										<tr>
											<td style="width: 100%;">hub (B) = 0.83</td>
										</tr>
										<tr>
											<td style="width: 100%;">hub (N) = 0.0</td>
										</tr>
									</tbody>
								</table>
								<p>Let's us now calculate the authority score.</p>
								<p>Since A is pointed to by A and B, we add the hubs score of A and B from previous round to get the new_auth score for A which is = 2</p>
								<p>Since B is pointed to by B, we add the hubs score of B from previous round to get the new_auth score for B which is = 1</p>
								<p>&nbsp;As N is pointed to by A and B both, we add the hubs score of A and B from previous round to get the new_auth score for N which is = 2</p>
								<p>The l2 norm for new_auth will be = &radic;(2^2 + 1^2 + 2^ 2) = 3</p>
								<p>Dividing each element of new_hub score, we have new auths score as follows:</p>
								<table style="border-collapse: collapse; width: 22.4014%; height: 72px;" height="77" border="1">
									<tbody>
										<tr style="height: 18px;">
											<td style="width: 100%; text-align: center; height: 18px;">Auth Score</td>
										</tr>
										<tr style="height: 18px;">
											<td style="width: 100%; height: 18px;">auth (A) = 0.67</td>
										</tr>
										<tr style="height: 18px;">
											<td style="width: 100%; height: 18px;">auth (B) = 0.33</td>
										</tr>
										<tr style="height: 18px;">
											<td style="width: 100%; height: 18px;">auth (N) = 0.67</td>
										</tr>
									</tbody>
								</table>
								<p>Thus round 1 end can be summarized as follows:</p>
								<table style="border-collapse: collapse; width: 46.8666%;" height="98" border="1">
									<tbody>
										<tr>
											<td style="width: 43.0337%; text-align: center;"><strong>Hubs score</strong></td>
											<td style="width: 47.1973%; text-align: center;"><strong>Auth score</strong></td>
										</tr>
										<tr>
											<td style="width: 43.0337%;">hub (A) = 0.55</td>
											<td style="width: 47.1973%;">auth (A) = 0.67</td>
										</tr>
										<tr>
											<td style="width: 43.0337%;">hub (B) = 0.83</td>
											<td style="width: 47.1973%;">auth (B) = 0.33</td>
										</tr>
										<tr>
											<td style="width: 43.0337%;">hub (N) = 0.0</td>
											<td style="width: 47.1973%;">auth (N) = 0.67</td>
										</tr>
									</tbody>
								</table>
								<p><strong>Round 2:&nbsp;</strong></p>
								<p>Similar to the previous round, we will calculate first the hubs score and then authority score. </p>
								<p>Since A points to A and N, we add the authority score of A and N from previous round to get the new _hub score for A which is = 0.67 + 0.67 = 1.34</p>
								<p>Since B points to A,B and N, the new_hub score for B&nbsp; = 0.67 + 0.33 + 0.67 = 1.67</p>
								<p>As N does not point to anything, the new_hub score for N = 0</p>
								<p>The l2 norm for new_hub is: &radic;(1.34^2 +1.67^2 + 0) = 2.14</p>
								<p>Dividing each element of new_hub score, we have new hub score as follows:</p>
								<table style="border-collapse: collapse; width: 22.4014%; height: 72px;" height="77" border="1">
									<tbody>
										<tr style="height: 18px;">
											<td style="width: 100%; text-align: center; height: 18px;">Hub Score</td>
										</tr>
										<tr style="height: 18px;">
											<td style="width: 100%; height: 18px;">hub (A) = 0.63</td>
										</tr>
										<tr style="height: 18px;">
											<td style="width: 100%; height: 18px;">hub (B) = 0.78</td>
										</tr>
										<tr style="height: 18px;">
											<td style="width: 100%; height: 18px;">hub (N) = 0.0</td>
										</tr>
									</tbody>
								</table>
								<p>Since A is pointed to by A and B, we add the hubs score of A and B from previous round to get the new_auth score for A which is = 0.55 + 0.83 = 1.38</p>
								<p>Since B is pointed to by B , the new_auth score for B&nbsp; = 0.83 </p>
								<p>As N is pointed to by A and B, the new_auth score for N = 0.55 + 0.83 = 1.38</p>
								<p>The l2 norm for new_auth is: &radic;(1.38^2 +0.83^2 + 1.38^2) = 2.12</p>
								<p>Dividing each element of new_auth score, we have new auth score as follows:</p>
								<table style="border-collapse: collapse; width: 22.4014%; height: 72px;" height="77" border="1">
									<tbody>
										<tr style="height: 18px;">
											<td style="width: 100%; text-align: center; height: 18px;">Hub Score</td>
										</tr>
										<tr style="height: 18px;">
											<td style="width: 100%; height: 18px;">auth (A) = 0.65</td>
										</tr>
										<tr style="height: 18px;">
											<td style="width: 100%; height: 18px;">auth (B) = 0.39</td>
										</tr>
										<tr style="height: 18px;">
											<td style="width: 100%; height: 18px;">auth (N) = 0.65</td>
										</tr>
									</tbody>
								</table>
								<p></p>
								<p>Thus round 2 end can be summarized as follows:</p>
								<table style="border-collapse: collapse; width: 46.8666%;" height="98" border="1">
									<tbody>
										<tr>
											<td style="width: 43.0337%; text-align: center;"><strong>Hubs score</strong></td>
											<td style="width: 47.1973%; text-align: center;"><strong>Auth score</strong></td>
										</tr>
										<tr>
											<td style="width: 43.0337%;">hub (A) = 0.63</td>
											<td style="width: 47.1973%;">auth (A) = 0.65</td>
										</tr>
										<tr>
											<td style="width: 43.0337%;">hub (B) = 0.78</td>
											<td style="width: 47.1973%;">auth (B) = 0.39</td>
										</tr>
										<tr>
											<td style="width: 43.0337%;">hub (N) = 0.0</td>
											<td style="width: 47.1973%;">auth (N) = 0.65</td>
										</tr>
									</tbody>
								</table>

								<p style="text-align: left;"><strong>Round 3</strong> Calculating in a similar manner we have,</p>
								<table style="border-collapse: collapse; width: 46.8666%;" height="98" border="1">
									<tbody>
										<tr>
											<td style="width: 43.0337%; text-align: center;"><strong>Hubs score</strong></td>
											<td style="width: 47.1973%; text-align: center;"><strong>Auth score</strong></td>
										</tr>
										<tr>
											<td style="width: 43.0337%;">hub (A) = 0.61</td>
											<td style="width: 47.1973%;">auth (A) = 0.66</td>
										</tr>
										<tr>
											<td style="width: 43.0337%;">hub (B) = 0.79</td>
											<td style="width: 47.1973%;">auth (B) = 0.36</td>
										</tr>
										<tr>
											<td style="width: 43.0337%;">hub (N) = 0.0</td>
											<td style="width: 47.1973%;">auth (N) = 0.66</td>
										</tr>
									</tbody>
								</table>

								<p style="text-align: left;"><strong>Round 4</strong></p>
								<table style="border-collapse: collapse; width: 46.8666%;" height="98" border="1">
									<tbody>
										<tr>
											<td style="width: 43.0337%; text-align: center;"><strong>Hubs score</strong></td>
											<td style="width: 47.1973%; text-align: center;"><strong>Auth score</strong></td>
										</tr>
										<tr>
											<td style="width: 43.0337%;">hub (A) = 0.62</td>
											<td style="width: 47.1973%;">auth (A) = 0.66</td>
										</tr>
										<tr>
											<td style="width: 43.0337%;">hub (B) = 0.79</td>
											<td style="width: 47.1973%;">auth (B) = 0.37</td>
										</tr>
										<tr>
											<td style="width: 43.0337%;">hub (N) = 0.0</td>
											<td style="width: 47.1973%;">auth (N) = 0.66</td>
										</tr>
									</tbody>
								</table>

								<p style="text-align: left;"><strong>Round 5</strong></p>
								<table style="border-collapse: collapse; width: 46.8666%;" height="98" border="1">
									<tbody>
										<tr>
											<td style="width: 43.0337%; text-align: center;"><strong>Hubs score</strong></td>
											<td style="width: 47.1973%; text-align: center;"><strong>Auth score</strong></td>
										</tr>
										<tr>
											<td style="width: 43.0337%;">hub (A) = 0.62</td>
											<td style="width: 47.1973%;">auth (A) = 0.66</td>
										</tr>
										<tr>
											<td style="width: 43.0337%;">hub (B) = 0.79</td>
											<td style="width: 47.1973%;">auth (B) = 0.37</td>
										</tr>
										<tr>
											<td style="width: 43.0337%;">hub (N) = 0.0</td>
											<td style="width: 47.1973%;">auth (N) = 0.66</td>
										</tr>
									</tbody>
								</table>
								<p>We can see that after Round 4 there is no change in the values of hub and authority score and thus they have converged.</p>
								<p>Page with highest hub score: BERT</p>
								<p>Page with highest authority score(s): attention and NMT</p>
								<p> The python code could be found here: <a href = "/code/hits.py" >hits.py</a> <br>

									References-<br>
									1. <a href="https://dl.acm.org/doi/abs/10.1145/324133.324140?casa_token=z68ds2yFtUsAAAAA%3ABDK2WRlc-erz1DQExuf5woXZDoYsLHEBuYCR7Irl1XfaqaBAIEqReJLre7YvDbb1adrCvQB1obxAEw">Authoritative sources in a hyperlinked environment-Jon Kleinberg </a> <br>
									2. <a href="http://pi.math.cornell.edu/~mec/Winter2009/RalucaRemus/Lecture4/lecture4.html">Cornell</a>
								</p>

							</div>

							<div class="w3-row">
								<div class="w3-col m8 s12">
									<p><button class="w3-button w3-padding-large w3-white w3-border" data-toggle="collapse" data-target="#more_5" onclick="new_expand(this)" id="5">READ MORE</button></p>
								</div>
								<div class="w3-col m4 w3-hide-small">
									<p><button class="w3-button w3-padding-large w3-border w3-right" onclick="expandComments(this)" id="5"><b>Comments  </b></button></p>
								</div>
							</div>
							<div class="w3-container utterances" id="comments_5" style="display:none;">
								<script src="https://utteranc.es/client.js" repo="manishpatel005/manishpatel005.github.io" issue-term="pathname" theme="github-light" crossorigin="anonymous" async>
								</script>
							</div>
						</div>
					</div>


					<!-- END BLOG ENTRIES -->
				</div>

				<!-- Introduction menu -->
				<div class="w3-col l3">
					<!-- About Card -->
					<div class="w3-card w3-margin w3-margin-top">
						<!--<img src="/w3images/avatar_g.jpg" style="width:100%"> -->
						<div class="w3-container w3-white">
							<h4><b>Manish Patel</b></h4>
							<p>Howdy!<br>
								My name is Manish and I am a software engineer in <a href="https://en.wikipedia.org/wiki/Computer_science#Computer_systems_and_computational_processes">Systems,</a> 
								and <a href="https://en.wikipedia.org/wiki/Information_retrieval">Information Retrieval</a>.
								I completed my Masters from Texas A&amp;M, US and  undergrad from NIT-Allahabad, India. <br>
                                Having brought-up in various parts of India, I enjoy traveling to new
								places and making new friends. In my free time, I love reading English
								classics,particulary realist fiction, and playing badminton.
								
							</p>
							<!--<p>Having brought-up in various parts of India, I enjoy traveling to new
								places and making new friends. In my free time, I love reading English
								classics,particulary realist fiction, and playing badminton. Some of
								my favorite books are - Anna Karenina, The Count of Monte Cristo, The
								Picture of Dorian Gray, 1984, Les Miserables, Karmabhoomi, The Art of
								War, Great Expectations, The Odyssey etc. In badminton, my favorite players are-
								Lee Chong Wei, Lin Dan(sad to hear his retirement), Kento Momota,
								PV Sindu and Victor Axelson.
                                Since my interests lie in the
								field of information retrieval, I couldn't find a better word than this to describe the blog.
								My intention of creating this blog is to share my enthusiasm and encourage people to generate
								new ideas to solve the challenging problems of today.
                                I love solving challenging problems and reading classics. 
							</p> -->
							<p>
								The name of this blog --The Anvikshik-- comes from a Sanskrit word Anviskhiki which roughly means the science of searching.
							</p>
						</div>
					</div>
					<hr>


					<!-- Posts -->
					<!-- 
<div class="w3-card w3-margin">
<div class="w3-container w3-padding">
<h4>Popular Posts</h4>
</div>
<ul class="w3-ul w3-hoverable w3-white">
<li class="w3-padding-16">
<img src="/w3images/workshop.jpg" alt="Image" class="w3-left w3-margin-right" style="width:50px">
<span class="w3-large">Lorem</span><br>
<span>Sed mattis nunc</span>
</li>
<li class="w3-padding-16">
<img src="/w3images/gondol.jpg" alt="Image" class="w3-left w3-margin-right" style="width:50px">
<span class="w3-large">Ipsum</span><br>
<span>Praes tinci sed</span>
</li> 
<li class="w3-padding-16">
<img src="/w3images/skies.jpg" alt="Image" class="w3-left w3-margin-right" style="width:50px">
<span class="w3-large">Dorum</span><br>
<span>Ultricies congue</span>
</li>   
<li class="w3-padding-16 w3-hide-medium w3-hide-small">
<img src="/w3images/rock.jpg" alt="Image" class="w3-left w3-margin-right" style="width:50px">
<span class="w3-large">Mingsum</span><br>
<span>Lorem ipsum dipsum</span>
</li>  
</ul>
</div>
<hr> 
-->
					<!-- Labels / tags -->
					<div class="w3-card w3-margin">
						<div class="w3-container w3-padding">
							<h4>Tags</h4>
						</div>
						<div class="w3-container w3-white">
							<p><span class="w3-tag w3-light-grey w3-margin-bottom">Information Retrieval</span> 
								<span class="w3-tag w3-light-grey w3-margin-bottom">SEO</span> 
								<span class="w3-tag w3-light-grey w3-margin-bottom">TF-IDF</span>
								<span class="w3-tag w3-light-grey w3-margin-bottom">Vector Space</span>
								<span class="w3-tag w3-light-grey w3-margin-bottom">BM25</span>
								<span class="w3-tag w3-light-grey w3-margin-bottom">Hubs and Authorities</span>
								<span class="w3-tag w3-light-grey w3-margin-bottom">HITS</span>
								<span class="w3-tag w3-light-grey w3-margin-bottom">PageRank</span>
								<span class="w3-tag w3-light-grey w3-margin-bottom">Google Search</span>
								<span class="w3-tag w3-light-grey w3-margin-bottom">Recommder Systems</span>
                                <span class="w3-tag w3-light-grey w3-margin-bottom">Obstacle Avoiding Robot</span>
                                <span class="w3-tag w3-light-grey w3-margin-bottom">Correlation vs Causation</span>
								<!--<span class="w3-tag w3-light-grey w3-small w3-margin-bottom"><img src="https://hitcounter.pythonanywhere.com/count/tag.svg" alt="Hits"></span>
-->
							</p>
						</div>
					</div>

					<!-- END Introduction Menu -->
				</div>

				<!-- END GRID -->
			</div><br>

			<!-- END w3-content -->
		</div>

		<!-- Footer -->
		<footer class="w3-container w3-dark-grey w3-padding-32 w3-margin-top">
			<button class="w3-button w3-black w3-disabled w3-padding-large w3-margin-bottom">Previous</button>
			<button class="w3-button w3-black w3-padding-large w3-margin-bottom" onclick="location.href='./blog_2.html'" type="button">Next »</button>
			<!--<p>Powered by <a href="https://www.w3schools.com/w3css/default.asp" target="_blank">w3.css</a></p> -->
		</footer>

		<script>
			function expandRead(button) {
				var id = button.id;
				var dots_id = 'dots_' + id;
				var more_id = 'more_' + id;


				var dots = document.getElementById(dots_id);
				var moreText = document.getElementById(more_id);
				var btnText = document.getElementById(id);


				if (dots.style.display === "none") {
					dots.style.display = "inline";
					btnText.innerHTML = "Read more";
					moreText.style.display = "none";

				} else {
					dots.style.display = "none";
					btnText.innerHTML = "Read less";
					moreText.style.display = "inline";
				}

			}

			function new_expand(button){
				var id = button.id;
				// Toggle button text
				var btnElem = document.getElementById(id);

				if (btnElem.innerHTML === "READ MORE"){
					btnElem.innerHTML = "READ LESS";
				} else {
					btnElem.innerHTML = "READ MORE";
				}

			}

			function expandComments(button) {
				var id = button.id;
				var comments_id = 'comments_' + id;
				var moreComments = document.getElementById(comments_id);

				if (moreComments.style.display === "none") {
					moreComments.style.display = "block";
				} else {
					moreComments.style.display = "none";
				}
			}


		</script>
	</body>

</html>
